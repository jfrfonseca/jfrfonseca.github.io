{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Comments to PANDAS\n",
    "\n",
    "So, my very beloved humanities-student girlfriend needed to study all the comments made on YouTube about this video.  \n",
    "And asked for my data-scientist help :)\n",
    "\n",
    "First thing I did was get on Google and search for \"python download YouTube comments\" and found this 2015 MIT-licensed python snipped by Egbert Bouman (@egbertbouman). It was very close to what I needed, because:\n",
    "- It **does not** uses YouTube's API, requiring no registration from the user\n",
    "- It's MIT-licensed, thereby compatible with my GF's academic needs\n",
    "- It does a viable scrapping from the browser-visible page itself\n",
    "- It returns the comments in a list-of-dicts format that can be easily exported to PANDAS, and then to MS Excel.\n",
    "- It also extracts the REPLIES to comments\n",
    "- It uses few dependencies, that can all be installed with the single line below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T23:35:40.157340Z",
     "start_time": "2018-03-04T23:35:38.264461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/zeff/anaconda3/lib/python3.6/site-packages\r\n",
      "Requirement already satisfied: cssselect in /home/zeff/anaconda3/lib/python3.6/site-packages\r\n",
      "Requirement already satisfied: lxml in /home/zeff/anaconda3/lib/python3.6/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install requests cssselect lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original July 27th, 2017 version can be found here, and a copy of it is in the \"code\" directory of my blog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T23:35:40.174176Z",
     "start_time": "2018-03-04T23:35:40.163192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zeff/Documents/jfrfonseca.github.io/code\n"
     ]
    }
   ],
   "source": [
    "cd ../code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, all I needed to do was get the YouTube ID of the video (all that goes after \"https://www.youtube.com/watch?v=\") and import @egbertbouman's **download_comments** function, run it, and put the resulting data in to a PANDAS DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T23:35:41.198605Z",
     "start_time": "2018-03-04T23:35:40.178941Z"
    }
   },
   "outputs": [],
   "source": [
    "# Python's standard library\n",
    "import datetime\n",
    "\n",
    "# PIP-available libraries\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# @egbertbouman's library\n",
    "from youtube_comments_downloader import download_comments\n",
    "\n",
    "# Video ID\n",
    "youtube_id = 'mC_vrzqYfQc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the comments to a list, noting the time\n",
    "now = datetime.datetime.utcnow()\n",
    "comments_list = download_comments(youtube_id)\n",
    "\n",
    "# Convert the list to a Pandas DataFrame\n",
    "df_comments = pd.DataFrame().from_dict(comments_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I just dump the received comments into an MS Excel file using pandas, saving the video ID and the date-time of access in the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T21:12:31.173417Z",
     "start_time": "2018-03-04T21:12:27.695577Z"
    }
   },
   "outputs": [],
   "source": [
    "df_comments.to_excel('youtube_comments_{}_{}.xlsx'.format(youtube_id, now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed 2 things gone unexpected:\n",
    "- There is a warning about a URL that could not be parsed by Excel.\n",
    "- Youtube's way of expressing when a comment was made is totally weird.\n",
    "\n",
    "No need to worry about the first one, I can do some parsing in PANDAS to solve the second.\n",
    "\n",
    "The CID column in the retrieved table contains values with a \"dot\". The comments with a dot are replies to a comment identified for the value before the dot, being the value after the dot an ID for the reply itself.\n",
    "\n",
    "The code below parses the relative date of posting the comment informed by YouTube into a date format, saving the parsed dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T22:55:40.795514Z",
     "start_time": "2018-03-04T22:55:40.139183Z"
    }
   },
   "outputs": [],
   "source": [
    "def comment_time(now, time_text):\n",
    "    time_text = time_text.replace(' (editado)', '')\n",
    "    splitted = time_text.split(' ')\n",
    "    if len(splitted) == 3:\n",
    "        value, unity, _ = tuple(splitted)\n",
    "        try:\n",
    "            value = int(value)\n",
    "        except:\n",
    "            return time_text\n",
    "        else:\n",
    "            if unity in 'segundo;segundos;second;seconds':\n",
    "                return now - relativedelta(seconds=value)\n",
    "            elif unity in 'minuto;minutos;minute;minutes':\n",
    "                t = now - relativedelta(minutes=value)\n",
    "                return datetime.datetime(year=t.year, month=t.month, day=t.day, hour=t.hour, minute=t.minute)\n",
    "            elif unity in 'hora;horas;hour;hours':\n",
    "                t = now - relativedelta(hours=value)\n",
    "                return datetime.datetime(year=t.year, month=t.month, day=t.day, hour=t.hour)\n",
    "            elif unity in 'dia;dias;day;days':\n",
    "                t = now - relativedelta(days=value)\n",
    "                return datetime.datetime(year=t.year, month=t.month, day=t.day)\n",
    "            elif unity in 'semana;semanas;week;weeks':\n",
    "                t = now - relativedelta(days=7*value)\n",
    "                return datetime.datetime(year=t.year, month=t.month, day=t.day)\n",
    "            elif unity in 'mes;mÃªs;meses;month;months':\n",
    "                t = now - relativedelta(months=value)\n",
    "                return datetime.datetime(year=t.year, month=t.month, day=t.day)\n",
    "            elif unity in 'ano;anos;year;years':\n",
    "                t = now - relativedelta(years=value)\n",
    "                return datetime.datetime(year=t.year, month=t.month, day=t.day)\n",
    "            else:\n",
    "                return time_text\n",
    "\n",
    "df_comments = df_comments.assign(probable_time=df_comments.time.apply(lambda tme: comment_time(now, tme)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T22:55:45.593781Z",
     "start_time": "2018-03-04T22:55:41.263835Z"
    }
   },
   "outputs": [],
   "source": [
    "df_comments.to_excel('youtube_comments_probable_time_{}_{}.xlsx'.format(youtube_id, now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analises\n",
    "\n",
    "Juuust cause I'm SUCH a great BF, I'm also adding some simple analises to the data I just collected.\n",
    "\n",
    "I used this list to remove stopwords, and also removed:\n",
    "- '', 'pra', 'vem', ',', 'vc', 'q', 'oq', 'oque', 'and'\n",
    "- any word with only 1 or 2 characters\n",
    "\n",
    "Then I normalized the words, removing spaces, punctuation and capitalization, and:\n",
    "- Counted how many times each word appeared\n",
    "- Counted how many comments each word appeared\n",
    "- Counted how many users have used each word\n",
    "- Identified the probable date of the first and last use of each word\n",
    "\n",
    "I hope its useful :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T23:55:20.873205Z",
     "start_time": "2018-03-04T23:55:19.516741Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import requests\n",
    "import re\n",
    "\n",
    "stopwords = requests.get('https://gist.githubusercontent.com/alopes/5358189/raw/2107d809cca6b83ce3d8e04dbd9463283025284f/stopwords.txt'\n",
    "                        ).text.replace(' ', '').splitlines()\n",
    "stopwords = set(stopwords).union({'', 'pra', 'vem', ',', 'vc', 'q', 'oq', 'oque', 'and'})\n",
    "\n",
    "word_list = ' '.join(df_comments.text.fillna('')).split(' ')\n",
    "word_list = [re.sub(r'\\W+', '', w.lower()) for w in word_list]\n",
    "\n",
    "word_count = Counter(word_list)\n",
    "keys = list(word_count.keys())\n",
    "for word in keys:\n",
    "    if (word.lower() in stopwords) or (len(word) < 3):\n",
    "        word_count.pop(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T23:56:37.899081Z",
     "start_time": "2018-03-04T23:55:20.876920Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b29a8881a24b7e8d45234524df919d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12315), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "normalized_text = df_comments.text.fillna('').apply(lambda w: re.sub(r'\\W+', '', w.lower()))\n",
    "\n",
    "def analize_one_word(word):\n",
    "    df_occurrences = df_comments[normalized_text.str.contains(word)]\n",
    "    return {\n",
    "        'word': word, 'count': word_count[word],\n",
    "        'number_of_comments': len(df_occurrences),\n",
    "        'number_of_users': len(df_occurrences.author.unique()),\n",
    "        'first_occurrence': df_occurrences.probable_time.min(),\n",
    "        'last_occurrence': df_occurrences.probable_time.max()\n",
    "    }\n",
    "\n",
    "import multiprocessing\n",
    "pool = multiprocessing.Pool(6)\n",
    "\n",
    "word_analisis_list = list(tqdm(pool.imap_unordered(analize_one_word, list(word_count.keys())),\n",
    "                               total=len(word_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T23:56:38.036307Z",
     "start_time": "2018-03-04T23:56:37.907728Z"
    }
   },
   "outputs": [],
   "source": [
    "df_analisis = pd.DataFrame().from_dict(word_analisis_list)\n",
    "df_analisis = df_analisis.set_index('word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T23:56:38.059432Z",
     "start_time": "2018-03-04T23:56:38.040543Z"
    }
   },
   "outputs": [],
   "source": [
    "df_analisis.to_excel('analisis_youtube_video_comments_{}_{}.xlsx'.format(youtube_id, now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
